// LLM Workspace Sandbox
//
// Treats all LLM-suggested paths as untrusted. Validates suggestions into
// `VirtualPath` values and performs I/O only through type-safe functions.

use anyhow::Result;
use jailed_path::{VirtualPath, VirtualRoot};
use std::fs;

#[derive(Clone)]
struct AiWorkspace;

fn main() -> Result<()> {
    // Prepare workspace
    fs::create_dir_all("llm_ws")?;
    let vroot: VirtualRoot<AiWorkspace> = VirtualRoot::try_new("llm_ws")?;

    // Simulated LLM suggestions (could be malicious)
    let suggestions = vec![
        "notes/today.txt",
        "../secrets/steal.txt", // traversal attempt
        "/absolute/path/hack.txt", // absolute attempt
        "results/run1/output.log",
    ];

    for s in suggestions {
        match vroot.try_virtual_path(s) {
            Ok(vp) => {
                println!("Suggestion '{s}' -> {vp}"); // virtual root path
                apply_suggestion(&vp)?;
            }
            Err(e) => println!("Rejected '{s}': {e}"),
        }
    }

    fs::remove_dir_all("llm_ws").ok();
    Ok(())
}

fn apply_suggestion(p: &VirtualPath<AiWorkspace>) -> Result<()> {
    // Create parent dir if needed
    if let Some(parent) = p.virtualpath_parent()? { parent.create_dir_all()?; }
    // Log, then write
    println!("Writing to system path: {}", p.systempath_to_string_lossy());
    p.write_string("Generated by LLM tool\n")?;
    Ok(())
}
